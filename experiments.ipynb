{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec035e6-6946-475b-a433-3a80bc2e0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_libraries.project_functions import *\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063b6a4-5189-48a6-b4b9-6683968b02b9",
   "metadata": {},
   "source": [
    "# data from MT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e20407-fe0e-47a5-8104-0b86684337ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adef77d8-1251-4f80-9605-2c7c92ad5fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Połączono z kontem\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3666, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# symbol = 'EURUSD.pro'\n",
    "data = get_historical_data() # D1\n",
    "# data_m5 = get_historical_data(timeframe=mt5.TIMEFRAME_M5, symbol=\"GER30\", start='2022-01-01')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79fecc-8eb0-467c-910b-ed8d8e3f0c8f",
   "metadata": {},
   "source": [
    "# experiments for manual selection of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafb9f5e-b94e-4f0e-ba6a-ba52cc6b5a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rebound_best_parameters = optimize_parameters(data, rebound_analysis, calculate_accumulated_price_changes,\n",
    "#                                               windows_size= [i for i in range(1, 366, 1)],\n",
    "#                                               bias= [i for i in range(1, 50, 1)]\n",
    "#                                                 )\n",
    "\n",
    "# print(f\"Najlepsze opcje: {rebound_best_parameters}\")\n",
    "rebound_best_parameters = {'window_size': 2, 'bias': 10}\n",
    "\n",
    "# Najlepsze opcje: {'window_size': 2, 'bias': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42d0b04-c9ce-4085-84f9-99ee1cf1571a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Desktop\\Data Science\\SDA\\currency_exchange\\function\\preprocess_function.py:413: FutureWarning:\n",
      "\n",
      "Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'sell' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8340.900000000009, 2724.3000000000093)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_data_optimize = define_level(data, rebound_best_parameters[\"window_size\"] ,\n",
    "                                  rebound_best_parameters[\"bias\"])\n",
    "\n",
    "rebound_data = rebound_analysis(current_data_optimize)\n",
    "current_score = calculate_accumulated_price_changes(rebound_data, princ=True)\n",
    "current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240ae672-a26e-4d32-a995-1f95619fee46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.40327332242238"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(current_score) / (len(data)  /(22 * 12 )) / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b20cbe-7c43-4f95-8c9b-f812aaf28b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95de8462-a850-4933-8497-93401ee52ea0",
   "metadata": {},
   "source": [
    "# Experiments with Genetic Algorithm for line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb05320f-c39a-41e9-9dbe-1565816ab7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeneticAlgorithm:\n",
    "#     \"\"\"\n",
    "#     A class representing a Genetic Algorithm for parameter optimization in trading strategies.\n",
    "\n",
    "#     Attributes:\n",
    "#         data (pd.DataFrame): The financial data used for analysis.\n",
    "#         analysis (callable): The analysis function to process the data.\n",
    "#         calculate (callable): The scoring function to evaluate the performance of parameter combinations.\n",
    "#         window_sizes (list): Possible values for the window size parameter.\n",
    "#         biases (list): Possible values for the bias parameter.\n",
    "#         best_individual (list): The best parameter combination found by the genetic algorithm.\n",
    "\n",
    "#     Methods:\n",
    "#         init_individual(individual_class): Initializes an individual for the genetic algorithm.\n",
    "#         evaluate(individual): Evaluates the fitness of an individual based on the provided scoring function.\n",
    "#         mutate(individual): Performs mutation on an individual to introduce diversity in the population.\n",
    "#         calculate_parameters(params): Calculates the score for a given set of parameters.\n",
    "#         run_genetic_algorithm(population_size, offspring_size, cx_probability, mut_probability, n_generations):\n",
    "#             Runs the genetic algorithm to find the best parameter combination.\n",
    "#         get_best_individual(): Returns the best parameter combination found by the genetic algorithm.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, data, analysis, calculate, window_sizes, biases=[1]):\n",
    "#         \"\"\"Initializes the GeneticAlgorithm instance.\n",
    "\n",
    "#         Args:\n",
    "#             data (pd.DataFrame): The financial data used for analysis.\n",
    "#             analysis (callable): The analysis function to process the data.\n",
    "#             calculate (callable): The scoring function to evaluate the performance of parameter combinations.\n",
    "#             window_sizes (list): Possible values for the window size parameter.\n",
    "#             biases (list, optional): Possible values for the bias parameter. Defaults to [1].\n",
    "#         \"\"\"\n",
    "#         # Initialize the GeneticAlgorithm instance with the provided parameters\n",
    "#         # Attribute Initialization:\n",
    "#         self.data = data\n",
    "#         self.analysis = analysis\n",
    "#         self.calculate = calculate\n",
    "#         self.window_sizes = window_sizes\n",
    "#         self.biases = biases\n",
    "#         self.best_individual = None\n",
    "\n",
    "#         # Problem Definition\n",
    "#         # Define the problem as a maximization problem\n",
    "#         creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "#         creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "#         # Toolbox Initialization\n",
    "#         # Create a toolbox with the necessary components\n",
    "#         self.toolbox = base.Toolbox()\n",
    "\n",
    "#         # Registering Functions in the Toolbox\n",
    "#         # Register an initialization method for individuals\n",
    "#         self.toolbox.register(\"individual\", self.init_individual, creator.Individual)\n",
    "        \n",
    "#         # Register a method to initialize a population of individuals\n",
    "#         self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        \n",
    "#         # Register the evaluation method for individuals\n",
    "#         self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "        \n",
    "#         # Register the crossover method using Blend Crossover with a specified alpha value\n",
    "#         self.toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "        \n",
    "#         # Register the mutation method\n",
    "#         self.toolbox.register(\"mutate\", self.mutate)\n",
    "        \n",
    "#         # Register the selection method using Tournament Selection with a tournament size of 3\n",
    "#         self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    \n",
    "#     def init_individual(self, individual_class):\n",
    "#         \"\"\"\n",
    "#         Initializes an individual for the genetic algorithm.\n",
    "\n",
    "#         Args:\n",
    "#             individual_class: The class representing an individual in the genetic algorithm.\n",
    "\n",
    "#         Returns:\n",
    "#             list: The initialized individual.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return individual_class([random.choice(self.window_sizes), random.choice(self.biases)])\n",
    "\n",
    "    \n",
    "#     def evaluate(self, individual):\n",
    "#         \"\"\"\n",
    "#         Evaluates the fitness of an individual based on the provided scoring function.\n",
    "\n",
    "#         Args:\n",
    "#             individual (list): The individual representing a parameter combination.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: The fitness score of the individual.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         window_size, bias = map(int, individual)\n",
    "#         params = {'window_size': window_size, 'bias': bias}\n",
    "#         score = self.calculate_parameters(params)\n",
    "#         return (score,)\n",
    "\n",
    "    \n",
    "#     def mutate(self, individual):\n",
    "#         \"\"\"\n",
    "#         Performs mutation on an individual to introduce diversity in the population.\n",
    "\n",
    "#         Args:\n",
    "#             individual (list): The individual to be mutated.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: The mutated individual.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if random.random() < 0.5:\n",
    "#             individual[0] = int(abs(individual[0] + random.randint(-5, 5)))\n",
    "#         else:\n",
    "#             individual[1] = random.choice(self.biases)\n",
    "#         return individual,\n",
    "\n",
    "    \n",
    "#     def calculate_parameters(self, params):\n",
    "#         \"\"\"\n",
    "#         Calculates the score for a given set of parameters.\n",
    "\n",
    "#         Args:\n",
    "#             params (dict): The parameter values.\n",
    "\n",
    "#         Returns:\n",
    "#             float: The calculated score.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         current_data = define_level(self.data, params['window_size'], params['bias'])\n",
    "#         rebound_data = self.analysis(current_data)\n",
    "#         return self.calculate(rebound_data)\n",
    "\n",
    "        \n",
    "#     def run_genetic_algorithm(self, population_size=10, offspring_size=50, cx_probability=0.7, mut_probability=0.2, n_generations=10):\n",
    "#         \"\"\"\n",
    "#         Runs the genetic algorithm to find the best parameter combination.\n",
    "\n",
    "#         Args:\n",
    "#             population_size (int, optional): The size of the initial population. Defaults to 10.\n",
    "#             offspring_size (int, optional): The size of the offspring population. Defaults to 50.\n",
    "#             cx_probability (float, optional): The crossover probability. Defaults to 0.7.\n",
    "#             mut_probability (float, optional): The mutation probability. Defaults to 0.2.\n",
    "#             n_generations (int, optional): The number of generations. Defaults to 10.\n",
    "\n",
    "#         Returns:\n",
    "#             list: The best parameter combination found by the genetic algorithm.\n",
    "#         \"\"\"\n",
    "#         # Create an initial population\n",
    "#         population = self.toolbox.population(n=population_size)\n",
    "\n",
    "#         # Run the genetic algorithm\n",
    "#         algorithms.eaMuPlusLambda(population, self.toolbox, mu=population_size, lambda_=offspring_size,\n",
    "#                                   cxpb=cx_probability, mutpb=mut_probability, ngen=n_generations, stats=None, halloffame=None)\n",
    "\n",
    "#         # Get the best individual\n",
    "#         self.best_individual = tools.selBest(population, k=1)[0]\n",
    "#         print(\"Best Parameters:\", self.best_individual)\n",
    "\n",
    "#         return self.best_individual\n",
    "\n",
    "    \n",
    "#     def get_best_individual(self):\n",
    "#         \"\"\"\n",
    "#         Returns the best parameter combination found by the genetic algorithm.\n",
    "\n",
    "#         Returns:\n",
    "#             list: The best parameter combination.\n",
    "#         \"\"\"\n",
    "#         return self.best_individual\n",
    "\n",
    "\n",
    "# # Example usage of the GeneticAlgorithm class\n",
    "# # Create an instance of the class\n",
    "# genetic_algorithm = GeneticAlgorithm(data, rebound_analysis, calculate_accumulated_price_changes, \n",
    "#                                      window_sizes= [i for i in range(1, 366, 1)], \n",
    "#                                      biases= [i for i in range(1, 50, 1)])\n",
    "\n",
    "\n",
    "# # Run the genetic algorithm\n",
    "# best_individual = genetic_algorithm.run_genetic_algorithm(population_size=10, \n",
    "#                                                           offspring_size=100, \n",
    "#                                                           cx_probability=0.7, \n",
    "#                                                           mut_probability=0.2, \n",
    "#                                                           n_generations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f8026a-bccd-426f-b99c-661d4474eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an instance of the class\n",
    "# genetic_algorithm = GeneticAlgorithm(data, rebound_analysis, calculate_accumulated_price_changes, \n",
    "#                                      window_sizes= [i for i in range(1, 366, 1)], \n",
    "#                                      biases= [i for i in range(1, 50, 1)])\n",
    "\n",
    "\n",
    "# # Run the genetic algorithm\n",
    "# best_individual = genetic_algorithm.run_genetic_algorithm(population_size=10, \n",
    "#                                                           offspring_size=100, \n",
    "#                                                           cx_probability=0.7, \n",
    "#                                                           mut_probability=0.2, \n",
    "#                                                           n_generations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "790c708b-8f3c-4757-bd06-bab4aaa0f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_data_algorithm = define_level(data,\n",
    "#                 ceil(genetic_algorithm.get_best_individual()[0]),\n",
    "#                 ceil(genetic_algorithm.get_best_individual()[1]) )\n",
    "\n",
    "# rebound_data = rebound_analysis(current_data_algorithm)\n",
    "# current_score = calculate_accumulated_price_changes(rebound_data, princ=True)\n",
    "# current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28239be8-a179-4040-a0ed-479791e82583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(current_score) / (data(data)  /(22 * 12 )) / 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16f5f1-b11a-4abd-92bc-fb2b2c52bd9e",
   "metadata": {},
   "source": [
    "# Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d50d1a6-9744-43de-b55f-485cf605518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automated_trading_from_signals(rebound_data, symbol= symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c6868-f11c-41f3-86cc-9d6e812ba100",
   "metadata": {},
   "source": [
    "# data preprocessing with class Preprocessing_stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a6b0690-8076-41b3-bb4f-5c9f8e568319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Połączono z kontem\n"
     ]
    }
   ],
   "source": [
    "del data\n",
    "data = get_historical_data() # D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154612ee-f9c4-4a54-9cb9-2a0e27ccd188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Tick_volume</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Real_volume</th>\n",
       "      <th>volume</th>\n",
       "      <th>MaxPositivePriceChange</th>\n",
       "      <th>MaxNegativePriceChange</th>\n",
       "      <th>PriceChange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2010-11-17</td>\n",
       "      <td>6674.9</td>\n",
       "      <td>6712.5</td>\n",
       "      <td>6659.5</td>\n",
       "      <td>6703.0</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>15.4</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2011-08-04</td>\n",
       "      <td>6700.7</td>\n",
       "      <td>6749.7</td>\n",
       "      <td>6271.9</td>\n",
       "      <td>6276.5</td>\n",
       "      <td>5315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>428.8</td>\n",
       "      <td>437.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>13130.5</td>\n",
       "      <td>13291.4</td>\n",
       "      <td>13102.4</td>\n",
       "      <td>13277.6</td>\n",
       "      <td>89612</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>160.9</td>\n",
       "      <td>28.1</td>\n",
       "      <td>252.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2011-08-01</td>\n",
       "      <td>7265.7</td>\n",
       "      <td>7298.5</td>\n",
       "      <td>6947.0</td>\n",
       "      <td>6989.0</td>\n",
       "      <td>4264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>351.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>318.7</td>\n",
       "      <td>164.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2011-08-10</td>\n",
       "      <td>5990.5</td>\n",
       "      <td>6117.7</td>\n",
       "      <td>5542.4</td>\n",
       "      <td>5610.4</td>\n",
       "      <td>7706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>575.3</td>\n",
       "      <td>127.2</td>\n",
       "      <td>448.1</td>\n",
       "      <td>400.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     open     high      low    close  Tick_volume  Spread  \\\n",
       "356  2010-11-17   6674.9   6712.5   6659.5   6703.0          780       0   \n",
       "538  2011-08-04   6700.7   6749.7   6271.9   6276.5         5315       0   \n",
       "2692 2020-02-04  13130.5  13291.4  13102.4  13277.6        89612       9   \n",
       "535  2011-08-01   7265.7   7298.5   6947.0   6989.0         4264       0   \n",
       "542  2011-08-10   5990.5   6117.7   5542.4   5610.4         7706       0   \n",
       "\n",
       "      Real_volume  volume  MaxPositivePriceChange  MaxNegativePriceChange  \\\n",
       "356             0    53.0                    37.6                    15.4   \n",
       "538             0   477.8                    49.0                   428.8   \n",
       "2692            0   189.0                   160.9                    28.1   \n",
       "535             0   351.5                    32.8                   318.7   \n",
       "542             0   575.3                   127.2                   448.1   \n",
       "\n",
       "      PriceChange  \n",
       "356          29.5  \n",
       "538         437.2  \n",
       "2692        252.7  \n",
       "535         164.4  \n",
       "542         400.3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_name = {'Open':'open', 'High' : 'high' , 'Low' : 'low', \n",
    "                'Close' : 'close', \"Volume\":\"volume\" }\n",
    "data = data.rename(columns= columns_name)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ac66af0-27c3-40ca-9cb6-47f85e5482d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing_stock_data(data)\n",
    "\n",
    "data_indicators_pattern  =  preprocessor.add_indicators_pattern_recognition_functions()\n",
    "data_calculate_overlap_studies  =  preprocessor.calculate_overlap_studies()\n",
    "data_math_operator_functions  =  preprocessor.math_operator_functions()\n",
    "data_math_transform_functions  =  preprocessor.math_transform_functions()\n",
    "data_momentum_indicator_functions  =  preprocessor.momentum_indicator_functions()\n",
    "data_statistic =  preprocessor.statistic_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a087d6b9-abfd-4401-be47-814cac802894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3666, 66)\n",
      "(3666, 38)\n",
      "(3666, 23)\n",
      "(3666, 23)\n",
      "(3666, 20)\n",
      "(3666, 65)\n",
      "(3666, 41)\n"
     ]
    }
   ],
   "source": [
    "print(data_indicators_pattern.shape)\n",
    "print(data_calculate_overlap_studies.shape)\n",
    "print(data_math_operator_functions.shape)\n",
    "print(data_math_operator_functions.shape)\n",
    "print(data_math_transform_functions.shape)\n",
    "print(data_momentum_indicator_functions.shape)\n",
    "print(data_statistic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e78acec-d3d1-4c8f-87dc-ed7544741b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>CDL2CROWS</th>\n",
       "      <th>CDL3BLACKCROWS</th>\n",
       "      <th>CDL3INSIDE</th>\n",
       "      <th>CDL3LINESTRIKE</th>\n",
       "      <th>CDL3OUTSIDE</th>\n",
       "      <th>...</th>\n",
       "      <th>CDLSPINNINGTOP</th>\n",
       "      <th>CDLSTALLEDPATTERN</th>\n",
       "      <th>CDLSTICKSANDWICH</th>\n",
       "      <th>CDLTAKURI</th>\n",
       "      <th>CDLTASUKIGAP</th>\n",
       "      <th>CDLTHRUSTING</th>\n",
       "      <th>CDLTRISTAR</th>\n",
       "      <th>CDLUNIQUE3RIVER</th>\n",
       "      <th>CDLUPSIDEGAP2CROWS</th>\n",
       "      <th>CDLXSIDEGAP3METHODS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>11019.4</td>\n",
       "      <td>11071.4</td>\n",
       "      <td>10863.6</td>\n",
       "      <td>10962.6</td>\n",
       "      <td>207.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>9641.3</td>\n",
       "      <td>9683.5</td>\n",
       "      <td>9537.0</td>\n",
       "      <td>9671.3</td>\n",
       "      <td>146.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>15750.0</td>\n",
       "      <td>15793.0</td>\n",
       "      <td>15712.0</td>\n",
       "      <td>15745.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5568.0</td>\n",
       "      <td>5584.0</td>\n",
       "      <td>5455.5</td>\n",
       "      <td>5511.5</td>\n",
       "      <td>128.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>9673.7</td>\n",
       "      <td>9849.8</td>\n",
       "      <td>9651.3</td>\n",
       "      <td>9849.0</td>\n",
       "      <td>198.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open     high      low    close  volume  CDL2CROWS  CDL3BLACKCROWS  \\\n",
       "1512  11019.4  11071.4  10863.6  10962.6   207.8          0               0   \n",
       "1246   9641.3   9683.5   9537.0   9671.3   146.5          0               0   \n",
       "3040  15750.0  15793.0  15712.0  15745.0    81.0          0               0   \n",
       "159    5568.0   5584.0   5455.5   5511.5   128.5          0               0   \n",
       "1398   9673.7   9849.8   9651.3   9849.0   198.5          0               0   \n",
       "\n",
       "      CDL3INSIDE  CDL3LINESTRIKE  CDL3OUTSIDE  ...  CDLSPINNINGTOP  \\\n",
       "1512           0               0            0  ...               0   \n",
       "1246           0               0            0  ...               0   \n",
       "3040           0               0            0  ...            -100   \n",
       "159            0               0            0  ...               0   \n",
       "1398           0               0            0  ...               0   \n",
       "\n",
       "      CDLSTALLEDPATTERN  CDLSTICKSANDWICH  CDLTAKURI  CDLTASUKIGAP  \\\n",
       "1512                  0                 0          0             0   \n",
       "1246                  0                 0          0             0   \n",
       "3040                  0                 0          0             0   \n",
       "159                   0                 0          0             0   \n",
       "1398                  0                 0          0             0   \n",
       "\n",
       "      CDLTHRUSTING  CDLTRISTAR  CDLUNIQUE3RIVER  CDLUPSIDEGAP2CROWS  \\\n",
       "1512             0           0                0                   0   \n",
       "1246             0           0                0                   0   \n",
       "3040             0           0                0                   0   \n",
       "159              0           0                0                   0   \n",
       "1398             0           0                0                   0   \n",
       "\n",
       "      CDLXSIDEGAP3METHODS  \n",
       "1512                    0  \n",
       "1246                    0  \n",
       "3040                    0  \n",
       "159                     0  \n",
       "1398                    0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_indicators_pattern.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71af09-f91e-4e14-b38d-8b331fc10f22",
   "metadata": {},
   "source": [
    "# experiments with RFELSTM and data from Preprocessing_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1d41e83e-ecae-40e7-9822-28bcfb65f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Attention\n",
    "from tensorflow.compat.v1.train import Optimizer\n",
    "from tensorflow.keras.models import clone_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "369c6962-7697-4112-b471-0fcd62844b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>CDL2CROWS</th>\n",
       "      <th>CDL3BLACKCROWS</th>\n",
       "      <th>CDL3INSIDE</th>\n",
       "      <th>CDL3LINESTRIKE</th>\n",
       "      <th>CDL3OUTSIDE</th>\n",
       "      <th>...</th>\n",
       "      <th>CDLSPINNINGTOP</th>\n",
       "      <th>CDLSTALLEDPATTERN</th>\n",
       "      <th>CDLSTICKSANDWICH</th>\n",
       "      <th>CDLTAKURI</th>\n",
       "      <th>CDLTASUKIGAP</th>\n",
       "      <th>CDLTHRUSTING</th>\n",
       "      <th>CDLTRISTAR</th>\n",
       "      <th>CDLUNIQUE3RIVER</th>\n",
       "      <th>CDLUPSIDEGAP2CROWS</th>\n",
       "      <th>CDLXSIDEGAP3METHODS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>9576.0</td>\n",
       "      <td>9680.3</td>\n",
       "      <td>9390.3</td>\n",
       "      <td>9679.3</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>7000.5</td>\n",
       "      <td>7041.3</td>\n",
       "      <td>6976.7</td>\n",
       "      <td>6986.2</td>\n",
       "      <td>64.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>15433.0</td>\n",
       "      <td>15533.2</td>\n",
       "      <td>15315.2</td>\n",
       "      <td>15424.2</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>13943.0</td>\n",
       "      <td>13971.0</td>\n",
       "      <td>13790.0</td>\n",
       "      <td>13910.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>6224.0</td>\n",
       "      <td>6251.5</td>\n",
       "      <td>6102.0</td>\n",
       "      <td>6124.5</td>\n",
       "      <td>149.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open     high      low    close  volume  CDL2CROWS  CDL3BLACKCROWS  \\\n",
       "1595   9576.0   9680.3   9390.3   9679.3   290.0          0               0   \n",
       "387    7000.5   7041.3   6976.7   6986.2    64.6          0               0   \n",
       "3214  15433.0  15533.2  15315.2  15424.2   218.0          0               0   \n",
       "2961  13943.0  13971.0  13790.0  13910.0   181.0          0               0   \n",
       "252    6224.0   6251.5   6102.0   6124.5   149.5          0               0   \n",
       "\n",
       "      CDL3INSIDE  CDL3LINESTRIKE  CDL3OUTSIDE  ...  CDLSPINNINGTOP  \\\n",
       "1595           0               0            0  ...               0   \n",
       "387            0               0            0  ...               0   \n",
       "3214           0               0          100  ...            -100   \n",
       "2961           0               0            0  ...               0   \n",
       "252            0               0            0  ...               0   \n",
       "\n",
       "      CDLSTALLEDPATTERN  CDLSTICKSANDWICH  CDLTAKURI  CDLTASUKIGAP  \\\n",
       "1595                  0                 0          0             0   \n",
       "387                   0                 0          0             0   \n",
       "3214                  0                 0          0             0   \n",
       "2961                  0                 0          0             0   \n",
       "252                   0                 0          0             0   \n",
       "\n",
       "      CDLTHRUSTING  CDLTRISTAR  CDLUNIQUE3RIVER  CDLUPSIDEGAP2CROWS  \\\n",
       "1595             0           0                0                   0   \n",
       "387              0           0                0                   0   \n",
       "3214             0           0                0                   0   \n",
       "2961             0           0                0                   0   \n",
       "252              0           0                0                   0   \n",
       "\n",
       "      CDLXSIDEGAP3METHODS  \n",
       "1595                    0  \n",
       "387                     0  \n",
       "3214                    0  \n",
       "2961                  100  \n",
       "252                     0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_indicators_pattern.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a6352-8354-42d7-b815-bcbccf89a0aa",
   "metadata": {},
   "source": [
    "## experiments № 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c327710-fce7-41d2-87b8-05cd319a8965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ef4ca687344c41bdcbedc53b4519c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 5ms/step\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0.]]], shape=(1, 25, 25), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1.]], shape=(1, 25), dtype=float32)\n",
      "23/23 [==============================] - 0s 6ms/step\n",
      "Removed feature at index 0. Test MSE before training: 137016.40555766737. Test MSE after training: 55837.526557338446\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:103\u001b[0m\n",
      "File \u001b[1;32m<timed exec>:59\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(self, X, y, num_features_to_keep, window_size, epochs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class AttentionRFE:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_data(self, window_size=25, y_column=\"close\"):\n",
    "        X, y = [], []\n",
    "    \n",
    "        for i in range(len(self.data) - window_size):\n",
    "            window = self.data.iloc[i:(i + window_size)].drop(y_column, axis=1)\n",
    "            X.append(window.values)\n",
    "            y.append(self.data.loc[i + window_size, y_column])\n",
    "    \n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "    \n",
    "        return self.X, self.y\n",
    "\n",
    "    def model_LSTM(self, shape: list[int, int]):\n",
    "        try:\n",
    "            input_layer = Input(shape = shape )\n",
    "            \n",
    "            lstm_layer = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "            output_tensor, weights = Attention()([lstm_layer, lstm_layer], return_attention_scores=True)\n",
    "            flatten_layer = Flatten()(output_tensor)\n",
    "            output_layer = Dense(1, activation='linear',)(flatten_layer)\n",
    "    \n",
    "            model = Model(inputs=input_layer, outputs=output_layer)\n",
    "            # model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    \n",
    "            self.model = model\n",
    "            return self.model\n",
    "    \n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            if self.X is None or self.y is None:\n",
    "                self.prepare_data()\n",
    "            return self.model_LSTM()\n",
    "\n",
    "    def fit(self, X=None, y=None, num_features_to_keep=1, window_size=25, epochs=10):\n",
    "        \n",
    "        if not X and not y:\n",
    "            self.prepare_data(window_size)\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "    \n",
    "        for _ in tqdm(range(self.X.shape[2] - num_features_to_keep)):\n",
    "            \n",
    "            model = clone_model(self.model_LSTM( shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    \n",
    "            # Обучение модели на текущих данных\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "            # Оценка модели на тестовых данных до обучения\n",
    "            y_pred_before = model.predict(X_test)\n",
    "            mse_before = mean_squared_error(y_test, y_pred_before)\n",
    "    \n",
    "            # Получение весов из слоя Attention\n",
    "            attention_layer = model.layers[2]\n",
    "    \n",
    "            # Предполагая, что attention_layer - это MultiHeadAttention слой из TensorFlow\n",
    "            _, attention_scores = attention_layer([X_test[:1], X_train[:1]], return_attention_scores=True)\n",
    "            print(attention_scores)\n",
    "\n",
    "    \n",
    "            # Суммирование весов по признакам\n",
    "            feature_importance = tf.reduce_sum(attention_scores, axis=2)\n",
    "            print(feature_importance)\n",
    "    \n",
    "    \n",
    "            # Находим индекс признака с наименьшим весом\n",
    "            idx_to_remove = np.argmin(feature_importance)\n",
    "            # print(idx_to_remove)\n",
    "    \n",
    "            # Удаляем признак с наименьшим весом из данных\n",
    "            X_train = np.delete(X_train, idx_to_remove, axis=2)\n",
    "            X_test = np.delete(X_test, idx_to_remove, axis=2)\n",
    "            \n",
    "    \n",
    "            # Обновление модели\n",
    "            model = clone_model(self.model_LSTM([X_train.shape[1], X_train.shape[2]] ))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "            \n",
    "            # Обучение модели на новых данных\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "            # Оценка модели на тестовых данных после обучения\n",
    "            y_pred_after = model.predict(X_test)\n",
    "            mse_after = mean_squared_error(y_test, y_pred_after)\n",
    "    \n",
    "            print(f\"Removed feature at index {idx_to_remove}. Test MSE before training: {mse_before}. Test MSE after training: {mse_after}\")\n",
    "\n",
    "\n",
    "# Создание экземпляра класса AttentionRFE\n",
    "rfe = AttentionRFE(data_indicators_pattern)\n",
    "rfe.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92649c47-8043-4014-a170-be3bf526f3c6",
   "metadata": {},
   "source": [
    "## experiments GradientRFE № 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e4032-fd3f-496e-8c68-19fe34d68644",
   "metadata": {},
   "source": [
    "Nasza warstwa Attention nie zachowuje się zbyt dziwnie i nie zwraca oczekiwanych danych.\n",
    "\n",
    "\"Problem z pierwszą częścią polega na tym, że usuwa tylko jedną cechę, a następnie ponownie przeprowadza wyszukiwanie i usuwa inną, i tak dalej do n. Jednak co, jeśli po połączeniu słabej cechy, która została wcześniej usunięta, z tymi, które pozostały po n iteracjach, wynik okazałby się lepszy? Konieczne jest opracowanie metody łączenia parametrów. Jednak implementacja czegoś takiego byłaby bardzo nieoptymalna, ponieważ czas wyszukiwania najlepszych parametrów wyniósłby n!, gdzie n to liczba cech. Spróbujmy podejść do zadania z innej strony\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc32f80-8272-49f9-9a4f-ef143a736258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import combinations\n",
    "\n",
    "# # Ваш список чисел\n",
    "# numbers = [1, 2, 3]\n",
    "\n",
    "# # Создание всех возможных комбинаций\n",
    "# all_combinations = []\n",
    "# for r in range(1, len(numbers) + 1):\n",
    "#     all_combinations.extend(combinations(numbers, r))\n",
    "\n",
    "# print(all_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95cae9-1e17-46b0-9a5f-869c4b071d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "class GradientRFE:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_data(self, window_size=25, y_column=\"close\"):\n",
    "        X, y = [], []\n",
    "    \n",
    "        for i in range(len(self.data) - window_size):\n",
    "            window = self.data.iloc[i:(i + window_size)].drop(y_column, axis=1)\n",
    "            X.append(window.values)\n",
    "            y.append(self.data.loc[i + window_size, y_column])\n",
    "    \n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "    \n",
    "        return self.X, self.y\n",
    "\n",
    "    def model_LSTM(self, shape: list[int, int]):\n",
    "        try:\n",
    "            input_layer = Input(shape = shape )\n",
    "            \n",
    "            lstm_layer = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "            output_tensor, weights = Attention()([lstm_layer, lstm_layer], return_attention_scores=True)\n",
    "            flatten_layer = Flatten()(output_tensor)\n",
    "            output_layer = Dense(1, activation='linear',)(flatten_layer)\n",
    "    \n",
    "            model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "            self.model = model\n",
    "            \n",
    "            return self.model\n",
    "    \n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            if self.X is None or self.y is None:\n",
    "                self.prepare_data()\n",
    "            return self.model_LSTM()\n",
    "\n",
    "            \n",
    "    def fit(self, X=None, y=None, num_features_to_keep=1, window_size=25, epochs=10):\n",
    "        \n",
    "        if not X and not y:\n",
    "            self.prepare_data(window_size)\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "    \n",
    "        for _ in tqdm(range(self.X.shape[2] - num_features_to_keep)):\n",
    "            \n",
    "            model = clone_model(self.model_LSTM( shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    \n",
    "            # Обучение модели на текущих данных\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "            \n",
    "            # # Оценка модели на тестовых данных до обучения\n",
    "            # y_pred_before = model.predict(X_test)\n",
    "            # mse_before = mean_squared_error(y_test, y_pred_before)\n",
    "    \n",
    "            # # Получение весов из слоя Attention\n",
    "            # attention_layer = model.layers[2]\n",
    "    \n",
    "            # # Предполагая, что attention_layer - это MultiHeadAttention слой из TensorFlow\n",
    "            # _, attention_scores = attention_layer([X_test[:1], X_train[:1]], return_attention_scores=True)\n",
    "            # # print(attention_scores)\n",
    "    \n",
    "            # # Суммирование весов по признакам\n",
    "            # feature_importance = tf.reduce_sum(attention_scores, axis=2)\n",
    "            # # print(feature_importance)\n",
    "    \n",
    "    \n",
    "            # # Находим индекс признака с наименьшим весом\n",
    "            # idx_to_remove = np.argmin(feature_importance)\n",
    "            # print(idx_to_remove)\n",
    "\n",
    "            \n",
    "    \n",
    "            # Удаляем признак с наименьшим весом из данных\n",
    "            X_train = np.delete(X_train, idx_to_remove, axis=2)\n",
    "            X_test = np.delete(X_test, idx_to_remove, axis=2)\n",
    "            \n",
    "    \n",
    "            # Обновление модели\n",
    "            model = clone_model(self.model_LSTM([X_train.shape[1], X_train.shape[2]] ))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "            \n",
    "            # Обучение модели на новых данных\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "            # Оценка модели на тестовых данных после обучения\n",
    "            y_pred_after = model.predict(X_test)\n",
    "            mse_after = mean_squared_error(y_test, y_pred_after)\n",
    "    \n",
    "            print(f\"Removed feature at index {idx_to_remove}. Test MSE before training: {mse_before}. Test MSE after training: {mse_after}\")\n",
    "    \n",
    "\n",
    "        column_names = list(data_indicators_pattern.columns)[:-1]  # Последняя колонка \"close\" не является признаком\n",
    "                \n",
    "        # Создание словаря, где ключи - названия колонок, значения - их важность (веса)\n",
    "        column_importance_dict = dict(zip(column_names, feature_importance[0]))\n",
    "        print(\"Важность признаков:\")\n",
    "        for column, importance in column_importance_dict.items():\n",
    "            print(f\"{column}: {importance}\")\n",
    "\n",
    "\n",
    "# Создание экземпляра класса AttentionRFE\n",
    "rfe = AttentionRFE(data_indicators_pattern)\n",
    "rfe.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd3de2-1de9-496e-b24d-6f1f9897216e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2fff95a3-05d8-4d76-92a7-f8cb1c9aa6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cccb84f6-c958-4621-b28a-3ff25763b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 8ms/step - loss: 1.6318\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.5756\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.5328\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.4893\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.4573\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4186\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.3879\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.3627\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3345\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.3134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Получение градиентов относительно входных данных\n",
    "with tf.GradientTape() as tape:\n",
    "    inputs = tf.convert_to_tensor(X_train)\n",
    "    tape.watch(inputs)\n",
    "    predictions = model(inputs)\n",
    "    loss = tf.reduce_mean(tf.square(predictions - y_train))\n",
    "\n",
    "gradients = tape.gradient(loss, inputs)\n",
    "\n",
    "# Рассчет абсолютных значений градиентов\n",
    "absolute_gradients = np.abs(gradients.numpy())\n",
    "# Усреднение важностей признаков\n",
    "average_importance = np.mean(absolute_gradients, axis=0)\n",
    "print(average_importance)\n",
    "# Предполагаем, что у вас есть массив average_importance\n",
    "index_of_min_value = np.argmin(average_importance)\n",
    "\n",
    "index_of_min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "464c319a-3226-4948-93f7-d5c3a5ff97cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0040035  0.00390094 0.00334264 0.00192257 0.00328265 0.00309102\n",
      " 0.00505311 0.0042888  0.00260999 0.00275602]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рассчет абсолютных значений градиентов\n",
    "absolute_gradients = np.abs(gradients.numpy())\n",
    "# Усреднение важностей признаков\n",
    "average_importance = np.mean(absolute_gradients, axis=0)\n",
    "print(average_importance)\n",
    "# Предполагаем, что у вас есть массив average_importance\n",
    "index_of_min_value = np.argmin(average_importance)\n",
    "\n",
    "index_of_min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9a58f-c274-418f-8200-9b647e87124d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8464d8-d757-4753-bd8e-091e1ddbaed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2685f9-36b1-4fc3-ba8d-424d37fc582e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85c610-447b-48f8-9277-336e0ffefd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f4a6e-9a68-4615-9ba9-3455f48d4423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f407f2b-7e11-4c01-bb2f-e04b33a05932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d64cb-a7ef-4873-9133-eb95f6be81ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d4e1c-273c-4c6b-8e2d-6449a6c1ce04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a866683-0e5f-43a4-92c4-a32211f870b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b03a9-ef5b-4b51-9281-01edf441daf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda649d8-9a28-49ce-9bfa-4bfa9680a92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46385c-e181-428c-9540-1a31afaf1dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa874f-236b-463a-bd00-358245437159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5c17d-d13a-4d68-83b1-794bee94f115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5e4e4-c2cd-4671-aa18-b6d1b5f1d4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b710f29-fb7d-416c-9279-ba368bb29464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fd647-b418-46b0-9e94-b0d6f9886287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c9cff-c7ab-4e8d-aa9f-270f3917e01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc8600-f32f-4fa1-9e2d-958a5578a104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dd023-9969-42ae-9eec-72fce39e2fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe69407-751b-48ca-af38-7ecee7afb310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bc0d4-cdaf-444f-affd-aaa10c3df22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4477c-2717-45c5-874a-82f873e2e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd20601-60bc-45ed-a6f3-dce79926c5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
