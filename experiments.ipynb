{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec035e6-6946-475b-a433-3a80bc2e0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_libraries.project_functions import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063b6a4-5189-48a6-b4b9-6683968b02b9",
   "metadata": {},
   "source": [
    "# data from MT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e20407-fe0e-47a5-8104-0b86684337ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef77d8-1251-4f80-9605-2c7c92ad5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symbol = 'EURUSD.pro'\n",
    "data = get_historical_data() # D1\n",
    "# data_m5 = get_historical_data(timeframe=mt5.TIMEFRAME_M5, symbol=\"GER30\", start='2022-01-01')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79fecc-8eb0-467c-910b-ed8d8e3f0c8f",
   "metadata": {},
   "source": [
    "# experiments for manual selection of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb9f5e-b94e-4f0e-ba6a-ba52cc6b5a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rebound_best_parameters = optimize_parameters(data, rebound_analysis, calculate_accumulated_price_changes,\n",
    "#                                               windows_size= [i for i in range(1, 366, 1)],\n",
    "#                                               bias= [i for i in range(1, 50, 1)]\n",
    "#                                                 )\n",
    "\n",
    "# print(f\"Najlepsze opcje: {rebound_best_parameters}\")\n",
    "rebound_best_parameters = {'window_size': 27, 'bias': 8}\n",
    "\n",
    "# Najlepsze opcje: {'window_size': 27, 'bias': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d0b04-c9ce-4085-84f9-99ee1cf1571a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "current_data_optimize = define_level(data, rebound_best_parameters[\"window_size\"] ,\n",
    "                                  rebound_best_parameters[\"bias\"])\n",
    "\n",
    "rebound_data = rebound_analysis(current_data_optimize)\n",
    "current_score = calculate_accumulated_price_changes(rebound_data, princ=True)\n",
    "current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ae672-a26e-4d32-a995-1f95619fee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(current_score) / (len(data)  /(22 * 12 )) / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b20cbe-7c43-4f95-8c9b-f812aaf28b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95de8462-a850-4933-8497-93401ee52ea0",
   "metadata": {},
   "source": [
    "# Experiments with Genetic Algorithm for line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05320f-c39a-41e9-9dbe-1565816ab7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GeneticAlgorithm:\n",
    "#     \"\"\"\n",
    "#     A class representing a Genetic Algorithm for parameter optimization in trading strategies.\n",
    "\n",
    "#     Attributes:\n",
    "#         data (pd.DataFrame): The financial data used for analysis.\n",
    "#         analysis (callable): The analysis function to process the data.\n",
    "#         calculate (callable): The scoring function to evaluate the performance of parameter combinations.\n",
    "#         window_sizes (list): Possible values for the window size parameter.\n",
    "#         biases (list): Possible values for the bias parameter.\n",
    "#         best_individual (list): The best parameter combination found by the genetic algorithm.\n",
    "\n",
    "#     Methods:\n",
    "#         init_individual(individual_class): Initializes an individual for the genetic algorithm.\n",
    "#         evaluate(individual): Evaluates the fitness of an individual based on the provided scoring function.\n",
    "#         mutate(individual): Performs mutation on an individual to introduce diversity in the population.\n",
    "#         calculate_parameters(params): Calculates the score for a given set of parameters.\n",
    "#         run_genetic_algorithm(population_size, offspring_size, cx_probability, mut_probability, n_generations):\n",
    "#             Runs the genetic algorithm to find the best parameter combination.\n",
    "#         get_best_individual(): Returns the best parameter combination found by the genetic algorithm.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, data, analysis, calculate, window_sizes, biases=[1]):\n",
    "#         \"\"\"Initializes the GeneticAlgorithm instance.\n",
    "\n",
    "#         Args:\n",
    "#             data (pd.DataFrame): The financial data used for analysis.\n",
    "#             analysis (callable): The analysis function to process the data.\n",
    "#             calculate (callable): The scoring function to evaluate the performance of parameter combinations.\n",
    "#             window_sizes (list): Possible values for the window size parameter.\n",
    "#             biases (list, optional): Possible values for the bias parameter. Defaults to [1].\n",
    "#         \"\"\"\n",
    "#         # Initialize the GeneticAlgorithm instance with the provided parameters\n",
    "#         # Attribute Initialization:\n",
    "#         self.data = data\n",
    "#         self.analysis = analysis\n",
    "#         self.calculate = calculate\n",
    "#         self.window_sizes = window_sizes\n",
    "#         self.biases = biases\n",
    "#         self.best_individual = None\n",
    "\n",
    "#         # Problem Definition\n",
    "#         # Define the problem as a maximization problem\n",
    "#         creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "#         creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "#         # Toolbox Initialization\n",
    "#         # Create a toolbox with the necessary components\n",
    "#         self.toolbox = base.Toolbox()\n",
    "\n",
    "#         # Registering Functions in the Toolbox\n",
    "#         # Register an initialization method for individuals\n",
    "#         self.toolbox.register(\"individual\", self.init_individual, creator.Individual)\n",
    "        \n",
    "#         # Register a method to initialize a population of individuals\n",
    "#         self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        \n",
    "#         # Register the evaluation method for individuals\n",
    "#         self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "        \n",
    "#         # Register the crossover method using Blend Crossover with a specified alpha value\n",
    "#         self.toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "        \n",
    "#         # Register the mutation method\n",
    "#         self.toolbox.register(\"mutate\", self.mutate)\n",
    "        \n",
    "#         # Register the selection method using Tournament Selection with a tournament size of 3\n",
    "#         self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    \n",
    "#     def init_individual(self, individual_class):\n",
    "#         \"\"\"\n",
    "#         Initializes an individual for the genetic algorithm.\n",
    "\n",
    "#         Args:\n",
    "#             individual_class: The class representing an individual in the genetic algorithm.\n",
    "\n",
    "#         Returns:\n",
    "#             list: The initialized individual.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         return individual_class([random.choice(self.window_sizes), random.choice(self.biases)])\n",
    "\n",
    "    \n",
    "#     def evaluate(self, individual):\n",
    "#         \"\"\"\n",
    "#         Evaluates the fitness of an individual based on the provided scoring function.\n",
    "\n",
    "#         Args:\n",
    "#             individual (list): The individual representing a parameter combination.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: The fitness score of the individual.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         window_size, bias = map(int, individual)\n",
    "#         params = {'window_size': window_size, 'bias': bias}\n",
    "#         score = self.calculate_parameters(params)\n",
    "#         return (score,)\n",
    "\n",
    "    \n",
    "#     def mutate(self, individual):\n",
    "#         \"\"\"\n",
    "#         Performs mutation on an individual to introduce diversity in the population.\n",
    "\n",
    "#         Args:\n",
    "#             individual (list): The individual to be mutated.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: The mutated individual.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         if random.random() < 0.5:\n",
    "#             individual[0] = int(abs(individual[0] + random.randint(-5, 5)))\n",
    "#         else:\n",
    "#             individual[1] = random.choice(self.biases)\n",
    "#         return individual,\n",
    "\n",
    "    \n",
    "#     def calculate_parameters(self, params):\n",
    "#         \"\"\"\n",
    "#         Calculates the score for a given set of parameters.\n",
    "\n",
    "#         Args:\n",
    "#             params (dict): The parameter values.\n",
    "\n",
    "#         Returns:\n",
    "#             float: The calculated score.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         current_data = define_level(self.data, params['window_size'], params['bias'])\n",
    "#         rebound_data = self.analysis(current_data)\n",
    "#         return self.calculate(rebound_data)\n",
    "\n",
    "        \n",
    "#     def run_genetic_algorithm(self, population_size=10, offspring_size=50, cx_probability=0.7, mut_probability=0.2, n_generations=10):\n",
    "#         \"\"\"\n",
    "#         Runs the genetic algorithm to find the best parameter combination.\n",
    "\n",
    "#         Args:\n",
    "#             population_size (int, optional): The size of the initial population. Defaults to 10.\n",
    "#             offspring_size (int, optional): The size of the offspring population. Defaults to 50.\n",
    "#             cx_probability (float, optional): The crossover probability. Defaults to 0.7.\n",
    "#             mut_probability (float, optional): The mutation probability. Defaults to 0.2.\n",
    "#             n_generations (int, optional): The number of generations. Defaults to 10.\n",
    "\n",
    "#         Returns:\n",
    "#             list: The best parameter combination found by the genetic algorithm.\n",
    "#         \"\"\"\n",
    "#         # Create an initial population\n",
    "#         population = self.toolbox.population(n=population_size)\n",
    "\n",
    "#         # Run the genetic algorithm\n",
    "#         algorithms.eaMuPlusLambda(population, self.toolbox, mu=population_size, lambda_=offspring_size,\n",
    "#                                   cxpb=cx_probability, mutpb=mut_probability, ngen=n_generations, stats=None, halloffame=None)\n",
    "\n",
    "#         # Get the best individual\n",
    "#         self.best_individual = tools.selBest(population, k=1)[0]\n",
    "#         print(\"Best Parameters:\", self.best_individual)\n",
    "\n",
    "#         return self.best_individual\n",
    "\n",
    "    \n",
    "#     def get_best_individual(self):\n",
    "#         \"\"\"\n",
    "#         Returns the best parameter combination found by the genetic algorithm.\n",
    "\n",
    "#         Returns:\n",
    "#             list: The best parameter combination.\n",
    "#         \"\"\"\n",
    "#         return self.best_individual\n",
    "\n",
    "\n",
    "# # Example usage of the GeneticAlgorithm class\n",
    "# # Create an instance of the class\n",
    "# genetic_algorithm = GeneticAlgorithm(data, rebound_analysis, calculate_accumulated_price_changes, \n",
    "#                                      window_sizes= [i for i in range(1, 366, 1)], \n",
    "#                                      biases= [i for i in range(1, 50, 1)])\n",
    "\n",
    "\n",
    "# # Run the genetic algorithm\n",
    "# best_individual = genetic_algorithm.run_genetic_algorithm(population_size=10, \n",
    "#                                                           offspring_size=100, \n",
    "#                                                           cx_probability=0.7, \n",
    "#                                                           mut_probability=0.2, \n",
    "#                                                           n_generations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8026a-bccd-426f-b99c-661d4474eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an instance of the class\n",
    "# genetic_algorithm = GeneticAlgorithm(data, rebound_analysis, calculate_accumulated_price_changes, \n",
    "#                                      window_sizes= [i for i in range(1, 366, 1)], \n",
    "#                                      biases= [i for i in range(1, 50, 1)])\n",
    "\n",
    "\n",
    "# # Run the genetic algorithm\n",
    "# best_individual = genetic_algorithm.run_genetic_algorithm(population_size=10, \n",
    "#                                                           offspring_size=100, \n",
    "#                                                           cx_probability=0.7, \n",
    "#                                                           mut_probability=0.2, \n",
    "#                                                           n_generations=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c708b-8f3c-4757-bd06-bab4aaa0f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_data_algorithm = define_level(data,\n",
    "#                 ceil(genetic_algorithm.get_best_individual()[0]),\n",
    "#                 ceil(genetic_algorithm.get_best_individual()[1]) )\n",
    "\n",
    "# rebound_data = rebound_analysis(current_data_algorithm)\n",
    "# current_score = calculate_accumulated_price_changes(rebound_data, princ=True)\n",
    "# current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28239be8-a179-4040-a0ed-479791e82583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(current_score) / (data(data)  /(22 * 12 )) / 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16f5f1-b11a-4abd-92bc-fb2b2c52bd9e",
   "metadata": {},
   "source": [
    "# Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50d1a6-9744-43de-b55f-485cf605518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automated_trading_from_signals(rebound_data, symbol= symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c6868-f11c-41f3-86cc-9d6e812ba100",
   "metadata": {},
   "source": [
    "# data preprocessing with class Preprocessing_stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b0690-8076-41b3-bb4f-5c9f8e568319",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "data = get_historical_data() # D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154612ee-f9c4-4a54-9cb9-2a0e27ccd188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_name = {'Open':'open', 'High' : 'high' , 'Low' : 'low', \n",
    "                'Close' : 'close', \"Volume\":\"volume\" }\n",
    "data = data.rename(columns= columns_name)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac66af0-27c3-40ca-9cb6-47f85e5482d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing_stock_data(data)\n",
    "\n",
    "data_indicators_pattern  =  preprocessor.add_indicators_pattern_recognition_functions()\n",
    "data_calculate_overlap_studies  =  preprocessor.calculate_overlap_studies()\n",
    "data_math_operator_functions  =  preprocessor.math_operator_functions()\n",
    "data_math_transform_functions  =  preprocessor.math_transform_functions()\n",
    "data_momentum_indicator_functions  =  preprocessor.momentum_indicator_functions()\n",
    "data_statistic =  preprocessor.statistic_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087d6b9-abfd-4401-be47-814cac802894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_indicators_pattern.shape)\n",
    "print(data_calculate_overlap_studies.shape)\n",
    "print(data_math_operator_functions.shape)\n",
    "print(data_math_operator_functions.shape)\n",
    "print(data_math_transform_functions.shape)\n",
    "print(data_momentum_indicator_functions.shape)\n",
    "print(data_statistic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78acec-d3d1-4c8f-87dc-ed7544741b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_math_transform_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b71af09-f91e-4e14-b38d-8b331fc10f22",
   "metadata": {},
   "source": [
    "# experiments with RFELSTM and data from Preprocessing_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369c6962-7697-4112-b471-0fcd62844b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_indicators_pattern.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a6352-8354-42d7-b815-bcbccf89a0aa",
   "metadata": {},
   "source": [
    "## experiments № 1 Attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c327710-fce7-41d2-87b8-05cd319a8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "class AttentionRFE:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_data(self, window_size=25, y_column=\"close\"):\n",
    "        X, y = [], []\n",
    "    \n",
    "        for i in range(len(self.data) - window_size):\n",
    "            window = self.data.iloc[i:(i + window_size)].drop(y_column, axis=1)\n",
    "            X.append(window.values)\n",
    "            y.append(self.data.loc[i + window_size, y_column])\n",
    "    \n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "    \n",
    "        return self.X, self.y\n",
    "\n",
    "    def model_LSTM(self, shape: list[int, int]):\n",
    "        try:\n",
    "            input_layer = Input(shape = shape )\n",
    "            \n",
    "            lstm_layer = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "            output_tensor, weights = Attention()([lstm_layer, lstm_layer], return_attention_scores=True)\n",
    "            flatten_layer = Flatten()(output_tensor)\n",
    "            output_layer = Dense(1, activation='linear',)(flatten_layer)\n",
    "    \n",
    "            model = Model(inputs=input_layer, outputs=output_layer)\n",
    "            # model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    \n",
    "            self.model = model\n",
    "            return self.model\n",
    "    \n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            if self.X is None or self.y is None:\n",
    "                self.prepare_data()\n",
    "            return self.model_LSTM()\n",
    "\n",
    "    def fit(self, X=None, y=None, num_features_to_keep=1, window_size=25, epochs=10):\n",
    "        \n",
    "        if not X and not y:\n",
    "            self.prepare_data(window_size)\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "    \n",
    "        for _ in tqdm(range(self.X.shape[2] - num_features_to_keep)):\n",
    "            \n",
    "            model = clone_model(self.model_LSTM( shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "    \n",
    "            # Обучение модели на текущих данных\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "            # Оценка модели на тестовых данных до обучения\n",
    "            y_pred_before = model.predict(X_test)\n",
    "            mse_before = mean_squared_error(y_test, y_pred_before)\n",
    "    \n",
    "            # Получение весов из слоя Attention\n",
    "            attention_layer = model.layers[2]\n",
    "    \n",
    "            # Предполагая, что attention_layer - это MultiHeadAttention слой из TensorFlow\n",
    "            _, attention_scores = attention_layer([X_test[:1], X_train[:1]], return_attention_scores=True)\n",
    "            print(attention_scores)\n",
    "\n",
    "    \n",
    "            # Суммирование весов по признакам\n",
    "            feature_importance = tf.reduce_sum(attention_scores, axis=2)\n",
    "            print(feature_importance)\n",
    "    \n",
    "    \n",
    "            # Находим индекс признака с наименьшим весом\n",
    "            idx_to_remove = np.argmin(feature_importance)\n",
    "            # print(idx_to_remove)\n",
    "    \n",
    "            # Удаляем признак с наименьшим весом из данных\n",
    "            X_train = np.delete(X_train, idx_to_remove, axis=2)\n",
    "            X_test = np.delete(X_test, idx_to_remove, axis=2)\n",
    "            \n",
    "    \n",
    "            # Обновление модели\n",
    "            model = clone_model(self.model_LSTM([X_train.shape[1], X_train.shape[2]] ))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "            \n",
    "            # Обучение модели на новых данных\n",
    "            model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "    \n",
    "            # Оценка модели на тестовых данных после обучения\n",
    "            y_pred_after = model.predict(X_test)\n",
    "            mse_after = mean_squared_error(y_test, y_pred_after)\n",
    "    \n",
    "            print(f\"Removed feature at index {idx_to_remove}. Test MSE before training: {mse_before}. Test MSE after training: {mse_after}\")\n",
    "\n",
    "\n",
    "## Создание экземпляра класса AttentionRFE\n",
    "            \n",
    "rfe = AttentionRFE(data_indicators_pattern)\n",
    "# rfe.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92649c47-8043-4014-a170-be3bf526f3c6",
   "metadata": {},
   "source": [
    "## experiments GradientRFE № 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e4032-fd3f-496e-8c68-19fe34d68644",
   "metadata": {},
   "source": [
    "Nasza warstwa Attention nie zachowuje się zbyt dziwnie i nie zwraca oczekiwanych danych.\n",
    "\n",
    "\"Problem z pierwszą częścią polega na tym, że usuwa tylko jedną cechę, a następnie ponownie przeprowadza wyszukiwanie i usuwa inną, i tak dalej do n. Jednak co, jeśli po połączeniu słabej cechy, która została wcześniej usunięta, z tymi, które pozostały po n iteracjach, wynik okazałby się lepszy? Konieczne jest opracowanie metody łączenia parametrów. Jednak implementacja czegoś takiego byłaby bardzo nieoptymalna, ponieważ czas wyszukiwania najlepszych parametrów wyniósłby n!, gdzie n to liczba cech. Spróbujmy podejść do zadania z innej strony\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b899b7-7cc7-4555-a1f8-ca0e39fa244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data_indicators_pattern  =  preprocessor.add_indicators_pattern_recognition_functions()\n",
    "data_calculate_overlap_studies  =  preprocessor.calculate_overlap_studies()\n",
    "data_math_operator_functions  =  preprocessor.math_operator_functions()\n",
    "data_math_transform_functions  =  preprocessor.math_transform_functions()\n",
    "data_momentum_indicator_functions  =  preprocessor.momentum_indicator_functions()\n",
    "data_statistic =  preprocessor.statistic_functions()\n",
    "\n",
    "\n",
    "data = [data_indicators_pattern, data_calculate_overlap_studies, data_math_operator_functions,\n",
    "        data_math_transform_functions, data_momentum_indicator_functions, data_statistic]\n",
    "\n",
    "data_name = [\"data_indicators_pattern\", \"data_calculate_overlap_studies\", \"data_math_operator_functions\",\n",
    "             \"data_math_transform_functions\", \"data_momentum_indicator_functions\", \"data_statistic\"]\n",
    "\n",
    "\n",
    "def process_dataframes(data:[pd.DataFrame], df_name:[str]) -> dict:\n",
    "\n",
    "    best_parameters = {}\n",
    "    for name, df in tqdm(zip(df_name, data)):\n",
    "        df = df.loc[:, df.nunique() != 1]\n",
    "        grfe = GradientRFE(df)  \n",
    "        grfe.fit() \n",
    "        best_parameters[name] = grfe.get_params()\n",
    "\n",
    "    return best_parameters\n",
    "\n",
    "\n",
    "best_parameters = process_dataframes(data, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2685f9-36b1-4fc3-ba8d-424d37fc582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_indicators_pattern  =  data_indicators_pattern.iloc[:, features_to_indicators_pattern]\n",
    "data_calculate_overlap_studies  =  data_calculate_overlap_studies.iloc[:, features_to_calculate_overlap_studi]\n",
    "data_math_operator_functions  =  data_math_operator_functions.iloc[:, features_to_math_operator_functions]\n",
    "data_math_transform_functions  =  data_math_transform_functions.iloc[:, features_to_math_transform_function]\n",
    "data_momentum_indicator_functions  =  data_momentum_indicator_functions.iloc[:, features_to_momentum_indicator_func]\n",
    "data_statistic =  data_statistic.iloc[:, features_to_statistic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df85c610-447b-48f8-9277-336e0ffefd3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_indicators_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f4a6e-9a68-4615-9ba9-3455f48d4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_statistic.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f407f2b-7e11-4c01-bb2f-e04b33a05932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d64cb-a7ef-4873-9133-eb95f6be81ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b03a9-ef5b-4b51-9281-01edf441daf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda649d8-9a28-49ce-9bfa-4bfa9680a92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46385c-e181-428c-9540-1a31afaf1dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa874f-236b-463a-bd00-358245437159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5c17d-d13a-4d68-83b1-794bee94f115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5e4e4-c2cd-4671-aa18-b6d1b5f1d4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b710f29-fb7d-416c-9279-ba368bb29464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fd647-b418-46b0-9e94-b0d6f9886287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c9cff-c7ab-4e8d-aa9f-270f3917e01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc8600-f32f-4fa1-9e2d-958a5578a104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416dd023-9969-42ae-9eec-72fce39e2fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe69407-751b-48ca-af38-7ecee7afb310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bc0d4-cdaf-444f-affd-aaa10c3df22c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4477c-2717-45c5-874a-82f873e2e15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd20601-60bc-45ed-a6f3-dce79926c5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
